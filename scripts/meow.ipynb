{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoConfig, AutoProcessor, AutoModelForVision2Seq)\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/miniconda3/envs/tensorrt-ecot/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "                        \"Embodied-CoT/ecot-openvla-7b-bridge\",\n",
    "                        trust_remote_code=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/miniconda3/envs/tensorrt-ecot/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file processor_config.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/processor_config.json\n",
      "loading configuration file preprocessor_config.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/preprocessor_config.json\n",
      "Image processor PrismaticImageProcessor {\n",
      "  \"auto_map\": {\n",
      "    \"AutoImageProcessor\": \"Embodied-CoT/ecot-openvla-7b-bridge--processing_prismatic.PrismaticImageProcessor\",\n",
      "    \"AutoProcessor\": \"Embodied-CoT/ecot-openvla-7b-bridge--processing_prismatic.PrismaticProcessor\"\n",
      "  },\n",
      "  \"image_processor_type\": \"PrismaticImageProcessor\",\n",
      "  \"image_resize_strategy\": \"letterbox\",\n",
      "  \"input_sizes\": [\n",
      "    [\n",
      "      3,\n",
      "      224,\n",
      "      224\n",
      "    ]\n",
      "  ],\n",
      "  \"interpolations\": [\n",
      "    \"bicubic\"\n",
      "  ],\n",
      "  \"means\": [\n",
      "    [\n",
      "      0.5,\n",
      "      0.5,\n",
      "      0.5\n",
      "    ]\n",
      "  ],\n",
      "  \"processor_class\": \"PrismaticProcessor\",\n",
      "  \"stds\": [\n",
      "    [\n",
      "      0.5,\n",
      "      0.5,\n",
      "      0.5\n",
      "    ]\n",
      "  ],\n",
      "  \"tvf_crop_params\": [\n",
      "    {\n",
      "      \"output_size\": [\n",
      "        224,\n",
      "        224\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"tvf_do_letterbox\": true,\n",
      "  \"tvf_letterbox_fill\": [\n",
      "    127,\n",
      "    127,\n",
      "    127\n",
      "  ],\n",
      "  \"tvf_normalize_params\": [\n",
      "    {\n",
      "      \"inplace\": false,\n",
      "      \"mean\": [\n",
      "        0.5,\n",
      "        0.5,\n",
      "        0.5\n",
      "      ],\n",
      "      \"std\": [\n",
      "        0.5,\n",
      "        0.5,\n",
      "        0.5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"tvf_resize_params\": [\n",
      "    {\n",
      "      \"antialias\": true,\n",
      "      \"interpolation\": 3,\n",
      "      \"max_size\": null,\n",
      "      \"size\": 224\n",
      "    }\n",
      "  ],\n",
      "  \"use_fused_vision_backbone\": false\n",
      "}\n",
      "\n",
      "loading file tokenizer.model from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/tokenizer.model\n",
      "loading file tokenizer.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/tokenizer.json\n",
      "loading file added_tokens.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/added_tokens.json\n",
      "loading file special_tokens_map.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/tokenizer_config.json\n",
      "loading configuration file processor_config.json from cache at /home/will/.cache/huggingface/hub/models--Embodied-CoT--ecot-openvla-7b-bridge/snapshots/492b3dbf3df380f6da333f86ce06dab028176166/processor_config.json\n",
      "Processor PrismaticProcessor:\n",
      "- image_processor: PrismaticImageProcessor {\n",
      "  \"auto_map\": {\n",
      "    \"AutoImageProcessor\": \"Embodied-CoT/ecot-openvla-7b-bridge--processing_prismatic.PrismaticImageProcessor\",\n",
      "    \"AutoProcessor\": \"Embodied-CoT/ecot-openvla-7b-bridge--processing_prismatic.PrismaticProcessor\"\n",
      "  },\n",
      "  \"image_processor_type\": \"PrismaticImageProcessor\",\n",
      "  \"image_resize_strategy\": \"letterbox\",\n",
      "  \"input_sizes\": [\n",
      "    [\n",
      "      3,\n",
      "      224,\n",
      "      224\n",
      "    ]\n",
      "  ],\n",
      "  \"interpolations\": [\n",
      "    \"bicubic\"\n",
      "  ],\n",
      "  \"means\": [\n",
      "    [\n",
      "      0.5,\n",
      "      0.5,\n",
      "      0.5\n",
      "    ]\n",
      "  ],\n",
      "  \"processor_class\": \"PrismaticProcessor\",\n",
      "  \"stds\": [\n",
      "    [\n",
      "      0.5,\n",
      "      0.5,\n",
      "      0.5\n",
      "    ]\n",
      "  ],\n",
      "  \"tvf_crop_params\": [\n",
      "    {\n",
      "      \"output_size\": [\n",
      "        224,\n",
      "        224\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"tvf_do_letterbox\": true,\n",
      "  \"tvf_letterbox_fill\": [\n",
      "    127,\n",
      "    127,\n",
      "    127\n",
      "  ],\n",
      "  \"tvf_normalize_params\": [\n",
      "    {\n",
      "      \"inplace\": false,\n",
      "      \"mean\": [\n",
      "        0.5,\n",
      "        0.5,\n",
      "        0.5\n",
      "      ],\n",
      "      \"std\": [\n",
      "        0.5,\n",
      "        0.5,\n",
      "        0.5\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"tvf_resize_params\": [\n",
      "    {\n",
      "      \"antialias\": true,\n",
      "      \"interpolation\": 3,\n",
      "      \"max_size\": null,\n",
      "      \"size\": 224\n",
      "    }\n",
      "  ],\n",
      "  \"use_fused_vision_backbone\": false\n",
      "}\n",
      "\n",
      "- tokenizer: LlamaTokenizerFast(name_or_path='Embodied-CoT/ecot-openvla-7b-bridge', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<PAD>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<PAD>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"processor_class\": \"PrismaticProcessor\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained( \"Embodied-CoT/ecot-openvla-7b-bridge\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting image...\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7fc5e445df80>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/MichalZawalski/embodied-CoT/main/test_obs.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m page \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt-ecot/lib/python3.10/site-packages/PIL/Image.py:3498\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3496\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3497\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3498\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7fc5e445df80>"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt-ecot/lib/python3.10/site-packages/PIL/Image.py:3277\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3277\u001b[0m     mode, rawmode \u001b[38;5;241m=\u001b[39m \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3278\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<f8')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeow meow meow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorrt-ecot/lib/python3.10/site-packages/PIL/Image.py:3281\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3279\u001b[0m         typekey_shape, typestr \u001b[38;5;241m=\u001b[39m typekey\n\u001b[1;32m   3280\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypekey_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypestr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   3282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3283\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f8"
     ]
    }
   ],
   "source": [
    "processor(\"Meow meow meow\", Image.fromarray(np.zeros([512, 256, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt-ecot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
